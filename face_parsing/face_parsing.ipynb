{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"face parsing\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIUlM5uGxKkQ"
      },
      "source": [
        "!git clone https://github.com/yandproject/CycleGAN-cartoon-reenactment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcs5kIq1ySDc"
      },
      "source": [
        "import os\n",
        "\n",
        "os.chdir('CycleGAN-cartoon-reenactment/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chuAL8cAnFkk"
      },
      "source": [
        "from face_parsing.logger import setup_logger\n",
        "from face_parsing.model import BiSeNet\n",
        "\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmAPAe2BOTWx",
        "outputId": "80487de2-07c9-47bf-c3a5-561ac9f5b5dc"
      },
      "source": [
        " from google.colab import drive \n",
        " drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5fdpNOcsUdA"
      },
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op0RM5eUnMMI"
      },
      "source": [
        "def vis_parsing_maps(im, parsing_anno, stride, save_im=False, save_path='vis_results/parsing_map_on_im.jpg'):\n",
        "    # Colors for all 20 parts\n",
        "    part_colors = [[255, 0, 0], [255, 85, 0], [255, 170, 0],\n",
        "                   [255, 0, 85], [255, 0, 170],\n",
        "                   [0, 255, 0], [85, 255, 0], [170, 255, 0],\n",
        "                   [0, 255, 85], [0, 255, 170],\n",
        "                   [0, 0, 255], [85, 0, 255], [170, 0, 255],\n",
        "                   [0, 85, 255], [0, 170, 255],\n",
        "                   [255, 255, 0], [255, 255, 85], [255, 255, 170],\n",
        "                   [255, 0, 255], [255, 85, 255], [255, 170, 255],\n",
        "                   [0, 255, 255], [85, 255, 255], [170, 255, 255]]\n",
        "\n",
        "    im = np.array(im)\n",
        "    vis_im = im.copy().astype(np.uint8)\n",
        "    vis_parsing_anno = parsing_anno.copy().astype(np.uint8)\n",
        "    vis_parsing_anno = cv2.resize(vis_parsing_anno, None, fx=stride, fy=stride, interpolation=cv2.INTER_NEAREST)\n",
        "    vis_parsing_anno_color = np.zeros((vis_parsing_anno.shape[0], vis_parsing_anno.shape[1], 3)) + 255\n",
        "\n",
        "    num_of_class = np.max(vis_parsing_anno)\n",
        "\n",
        "    for pi in range(1, num_of_class + 1):\n",
        "        index = np.where(vis_parsing_anno == pi)\n",
        "        vis_parsing_anno_color[index[0], index[1], :] = part_colors[pi]\n",
        "\n",
        "    vis_parsing_anno_color = vis_parsing_anno_color.astype(np.uint8)\n",
        "    # print(vis_parsing_anno_color.shape, vis_im.shape)\n",
        "    vis_im = cv2.addWeighted(cv2.cvtColor(vis_im, cv2.COLOR_RGB2BGR), 0.4, vis_parsing_anno_color, 0.6, 0)\n",
        "\n",
        "    # Save result or not\n",
        "    if save_im:\n",
        "        cv2.imwrite(save_path[:-4] +'.png', vis_parsing_anno)\n",
        "        cv2.imwrite(save_path, vis_im, [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
        "\n",
        "    # return vis_im\n",
        "\n",
        "def evaluate(respth='/content/drive/MyDrive/Results/', dspth='./data', cp='model_final_diss.pth'):\n",
        "\n",
        "    if not os.path.exists(respth):\n",
        "        os.makedirs(respth)\n",
        "\n",
        "    n_classes = 19\n",
        "    net = BiSeNet(n_classes=n_classes)\n",
        "    net.cuda()\n",
        "    save_pth = osp.join('/content/drive/MyDrive/Results/', cp)\n",
        "    net.load_state_dict(torch.load(save_pth))\n",
        "    net.eval()\n",
        "\n",
        "    to_tensor = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "    with torch.no_grad():\n",
        "        for image_path in os.listdir(dspth):\n",
        "            img = Image.open(osp.join(dspth, image_path))\n",
        "            image = img.resize((256, 256), Image.BILINEAR)\n",
        "            img = to_tensor(image)\n",
        "            img = torch.unsqueeze(img, 0)\n",
        "            img = img.cuda()\n",
        "            out = net(img)[0]\n",
        "            parsing = out.squeeze(0).cpu().numpy().argmax(0)\n",
        "            # print(parsing)\n",
        "            print(np.unique(parsing))\n",
        "\n",
        "            vis_parsing_maps(image, parsing, stride=1, save_im=True, save_path=osp.join(respth, image_path))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2Rb5FVS9gFZ"
      },
      "source": [
        "You can download pre-trained model for face parsing [here](https://drive.google.com/file/d/154JgKpzCPW82qINcVieuPH3fZ2e0P812/view)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaM5MhwkNtBN"
      },
      "source": [
        "#test\n",
        "if __name__ == \"__main__\":\n",
        "    evaluate(dspth='/content/drive/MyDrive/dataset/', cp=' 'your path to the file'/79999_iter.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv63Vkn9dqvz"
      },
      "source": [
        "img = Image.open('/content/drive/MyDrive/Results/'filename'.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9bUrbYfh__Q"
      },
      "source": [
        "l = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQpX6jbHePYF"
      },
      "source": [
        "for i in range(0, 256):\n",
        "  for j in range(0, 256):\n",
        "    l.append((img.convert('RGB').getpixel((j, i))[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAlKlHzqmS-q"
      },
      "source": [
        "mask = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGBmb_mIltFT"
      },
      "source": [
        "for i in range(0, 256*256):\n",
        "  if l[i] in [4, 5, 6, 11, 12, 13]:\n",
        "    mask.append(8)\n",
        "  else:\n",
        "    mask.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTlCxOB_8WUd"
      },
      "source": [
        "mask = np.resize(mask, (256, 256))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8Jz2FX73Ps5"
      },
      "source": [
        "ones = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcBG_VVA5N11"
      },
      "source": [
        "for i in range(0, 256):\n",
        "  ones.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiNcpl3M6Wkq"
      },
      "source": [
        "w = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaqqOzMY6EUa"
      },
      "source": [
        "for i in range(0, 256):\n",
        "  for j in range(0, 256):\n",
        "    ww = []\n",
        "    if mask[i][j] != 1:\n",
        "      ww.append(i)\n",
        "      ww.append(j)\n",
        "      ww.append(mask[i][j])\n",
        "      w.append(ww)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU1E3rK-Co6b"
      },
      "source": [
        "cuda0 = torch.device('cuda:0')\n",
        "a = torch.ones([1, 3, 256, 256], dtype=torch.float, device=cuda0)\n",
        "\n",
        "for element in w:\n",
        "    i = element[0]\n",
        "    j = element[1]\n",
        "    weight = element[2]\n",
        "    \n",
        "    a[0][0][i][j] = weight\n",
        "    a[0][1][i][j] = weight\n",
        "    a[0][2][i][j] = weight\n",
        "\n",
        "weights_1 = a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEgtmkDrC4vC"
      },
      "source": [
        "torch.save(weights_1, 'weights_1.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUxNgP8UDjJl"
      },
      "source": [
        "cuda0 = torch.device('cuda:0')\n",
        "\n",
        "b = torch.ones([1, 1, 256, 256], dtype=torch.float, device=cuda0)\n",
        "\n",
        "for element in w:\n",
        "    i = element[0]\n",
        "    j = element[1]\n",
        "    weight = element[2]\n",
        "    \n",
        "    b[0][0][i][j] = weight\n",
        "weights_0 = b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zFEf_VvD_15"
      },
      "source": [
        "torch.save(weights_0, 'weights_0.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr1Lp_KfECN_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}